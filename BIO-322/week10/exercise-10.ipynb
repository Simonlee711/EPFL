{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises - Week 10 - Non-linear Methods\n",
    "#### Simon Lee, BIO-322, Machine Learning for Bioengineers, Winter 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual\n",
    "#### Exercise 1\n",
    "Here below is an image (with padding 1 already applied; padding 1 means that one row/column of zeros is added to the top and bottom/left and right of the original image.). We would like to process it with a convolutional network with one convolution layer with two $3 \\\\times 3$ filters (depicted below the image), stride 1 and relu non-linearity (stride 1 means that the filter moves 1 position between each application, as in the formula in the slides).\n",
    "- Determine the width, height and depth of the volume after the convolutional layer.\n",
    "- Compute the output of the convolutional layer assuming the two biases to be zero.\n",
    "$(MLCourse.embed_figure(\"conv_exercise.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "After the convolutional layer the dimension will be $4 \\times 4 \\times 2$;\n",
    "$4\\times 4$ because this is the number of positions the $3\\times3$ filters can be applied at (with stride 1 and padding 1) and 2, because there are two filters.\n",
    "\n",
    "For filter 1\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "3  & 3 & 5 & 1\\\\\n",
    "7 & 4 & 4 & 5 \\\\\n",
    "2 & 7 & 5 & 3 \\\\\n",
    "4 & 3 & 2 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and for filter 2\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2  & 5 & 2 & 4\\\\\n",
    "8 & 9 & 5 & 7 \\\\\n",
    "7 & 3 & 4 & 6 \\\\\n",
    "5 & 2 & 5 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied\n",
    "#### Exercise 2\n",
    "In this exercise our goal is to find a good machine learning model to classify images of Zalando's articles. You can load a description of the so-called Fashion-MNIST data set with `OpenML.describe_dataset(40996)` and load the data set with `OpenML.load(40996)`. Take our recipe for supervised learning (last slide of the presentation on \\\"Model Assessment and Hyperparameter Tuning\\\") as a guideline. Hints: cleaning is not necessary, but plotting some examples is advisable; linear classification is a good starting point for a first benchmark, but you should also explore other models like random forests (`RandomForestClassifier`), multilayer perceptrons (`NeuralNetworkClassifier`) and convolutional neural networks (`ImageClassifer`) and play manually a bit with their hyper-parameters (proper tuning with `TunedModel` may be too time-intensive). To reduce the computation time, we will only use the first 5000 images of the full dataset for training and we will not do cross-validation here but instead use samples 5001 to 10000 as a validation set to estimate the classification accuracy. *Hint:* you can use the resampling strategy `Holdout` for model tuning and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/dev/MLCourse`\n"
     ]
    }
   ],
   "source": [
    "begin\n",
    "    using Pkg\n",
    "    Pkg.activate(joinpath(Pkg.devdir(), \"MLCourse\"))\n",
    "    using DataFrames, MLJ, MLJLinearModels, MLCourse, Random, Distributions, Plots, MLJFlux, Flux, OpenML, MLJDecisionTreeInterface\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\textbf{Author}: Han Xiao, Kashif Rasul, Roland Vollgraf   \\textbf{Source}: \\href{https://github.com/zalandoresearch/fashion-mnist}{Zalando Research}   \\textbf{Please cite}: Han Xiao and Kashif Rasul and Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, arXiv, cs.LG/1708.07747  \n",
       "\n",
       "Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. \n",
       "\n",
       "Raw data available at: https://github.com/zalandoresearch/fashion-mnist\n",
       "\n",
       "\\subsubsection{Target classes}\n",
       "Each training and test example is assigned to one of the following labels: Label  Description   0  T-shirt/top   1  Trouser   2  Pullover   3  Dress   4  Coat   5  Sandal   6  Shirt   7  Sneaker   8  Bag   9  Ankle boot\n",
       "\n"
      ],
      "text/markdown": [
       "**Author**: Han Xiao, Kashif Rasul, Roland Vollgraf   **Source**: [Zalando Research](https://github.com/zalandoresearch/fashion-mnist)   **Please cite**: Han Xiao and Kashif Rasul and Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, arXiv, cs.LG/1708.07747  \n",
       "\n",
       "Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. \n",
       "\n",
       "Raw data available at: https://github.com/zalandoresearch/fashion-mnist\n",
       "\n",
       "### Target classes\n",
       "\n",
       "Each training and test example is assigned to one of the following labels: Label  Description   0  T-shirt/top   1  Trouser   2  Pullover   3  Dress   4  Coat   5  Sandal   6  Shirt   7  Sneaker   8  Bag   9  Ankle boot\n"
      ],
      "text/plain": [
       "  \u001b[1mAuthor\u001b[22m: Han Xiao, Kashif Rasul, Roland Vollgraf \u001b[1mSource\u001b[22m: Zalando Research\n",
       "  (https://github.com/zalandoresearch/fashion-mnist) \u001b[1mPlease cite\u001b[22m: Han Xiao and\n",
       "  Kashif Rasul and Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for\n",
       "  Benchmarking Machine Learning Algorithms, arXiv, cs.LG/1708.07747\n",
       "\n",
       "  Fashion-MNIST is a dataset of Zalando's article images, consisting of a\n",
       "  training set of 60,000 examples and a test set of 10,000 examples. Each\n",
       "  example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "  Fashion-MNIST is intended to serve as a direct drop-in replacement for the\n",
       "  original MNIST dataset for benchmarking machine learning algorithms. It\n",
       "  shares the same image size and structure of training and testing splits.\n",
       "\n",
       "  Raw data available at: https://github.com/zalandoresearch/fashion-mnist\n",
       "\n",
       "\u001b[1m  Target classes\u001b[22m\n",
       "\u001b[1m  ––––––––––––––––\u001b[22m\n",
       "\n",
       "  Each training and test example is assigned to one of the following labels:\n",
       "  Label Description 0 T-shirt/top 1 Trouser 2 Pullover 3 Dress 4 Coat 5 Sandal\n",
       "  6 Shirt 7 Sneaker 8 Bag 9 Ankle boot"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenML.describe_dataset(40996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes significant time to load for your own discretion\n",
    "fashion = OpenML.load(40996) |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look a bit at the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(maximum(Array(fashion[:, 1:end-1])), minimum(Array(fashion[:, 1:end-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for MNIST, the images seem to be encoded with number between 0 and 255. Let us therefore transform scale the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "\tfashion_input = select(fashion[1:10000, :], Not(:class)) ./ 255\n",
    "\ttrain_input = fashion_input[1:5000, :]\n",
    "\ttest_input = fashion_input[5001:end, :]\n",
    "\ttrain_class = fashion.class[1:5000]\n",
    "\ttest_class = fashion.class[5001:10000]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = coerce(PermutedDimsArray(reshape(Array(fashion_input), :, 28, 28),\n",
    "                                  (3, 2, 1)),\n",
    "                GrayImage);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([plot(images[i]) for i in 1:12]..., layout = (3, 4), ticks = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = machine(LogisticClassifier(lambda = 1e-4), train_input, train_class) |> fit!;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(predict_mode(m1, test_input) .== test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy of linear classification with a little bit of L2 regularization (regularization constant $\\lambda = 10^{-4}$) is approximately 81%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = machine(RandomForestClassifier(n_trees = 500), train_input, train_class) |> fit!;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(predict_mode(m2, test_input) .== test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy of a random forest with 500 trees is slightly better than with the linear method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = machine(NeuralNetworkClassifier(builder = MLJFlux.Short(n_hidden = 128,\n",
    "                                                             dropout = 0.1,\n",
    "                                                             σ = relu),\n",
    "                                    batch_size = 32,\n",
    "                                    epochs = 30),\n",
    "             train_input, train_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(m3, verbosity = 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(predict_mode(m3, test_input) .== test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve with a multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    f() = 0\n",
    "    builder = MLJFlux.@builder(\n",
    "                  begin\n",
    "                      front = Chain(Conv((5, 5), n_channels => 16, relu),\n",
    "                                    Conv((3, 3), 16 => 32, relu),\n",
    "                                    Flux.flatten)\n",
    "                      d = first(Flux.outputsize(front, (n_in..., n_channels, 1)))\n",
    "                      Chain(front, Dropout(0.1), Dense(d, n_out))\n",
    "                  end)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = machine(ImageClassifier(builder = builder,\n",
    "                             batch_size = 32,\n",
    "                             epochs = 20),\n",
    "             images[1:5000], train_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(m4, verbosity = 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean(predict_mode(m4, images[5001:end]) .== test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this convolutional network we reach almost 85%. With further hyper-parameter tuning we expect even better results for the convolutional network.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
