{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises - Week 4 - Model Flexibility & Bias Variance Decomposition\n",
    "#### Simon Lee, BIO-322, Machine Learning for Bioengineers, Winter 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual\n",
    "#### Exercise 1\n",
    "For each example below, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "+ The sample size n is extremely large, and the number of predictors $p$ is small.\n",
    "+ The number of predictors $p$ is extremely large, and the number of observations $n$ is small.\n",
    "+ The relationship between the predictors and response is highly non-linear.\n",
    "+ The variance of the error terms, i.e. $\\sigma^2 = Var(\\epsilon)$, is extremely high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "* A flexible method would be better. A flexible method will fit the data closer, and with $n\\\\gg p` the risk of overfitting is small.\n",
    "* A flexible method would be worse. Because a flexible method fits the data closer, it is more likely to overfit when there is a small number of observations compared to the number of predictors.\n",
    "* A flexible method is better. With more degrees of freedom, a flexible method is more capable of producing highly non-linear behavior than an inflexible method.\n",
    "* A flexible method is worse. If observations are very noisy, a flexible method is more likely to fit to the noise and thereby overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "The table below provides a training data set containing six observations, three predictors, and one qualitative response variable. Suppose we wish to use this data set to make a prediction for $Y$ when $X_1 = X_2 = X_3 = 0$ using K-nearest neighbors.\n",
    "- Compute the Euclidean distance between each observation and the test point, X1 = X2 = X3 = 0.\n",
    "- What is our prediction with K = 1? Why?\n",
    "- What is our prediction with K = 3? Why?\n",
    "- If the decision boundary at threshold 0.5 in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?\n",
    "\n",
    "|Obs.|$X_1$|$X_2$|$X_3$|$Y$|\n",
    "|:----|-------|-------|-------|-----:|\n",
    "|1 | 0 | 3 | 0 | Red|\n",
    "|2 | 2 | 0 | 0 | Red|\n",
    "|3 | 0 | 1 | 3 | Red|\n",
    "|4 | 0 | 1 | 2 | Green|\n",
    "|5 | -1| 0 | 1 | Green|\n",
    "|6 | 1 | 1 | 1 | Red|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "* $d_1 = 3, d_2 = 2, d_3 = \\ \\sqrt{10}, d_4 = \\ \\sqrt{5}, d_5 = \\ \\sqrt{2}, d_6 = \\ \\sqrt{3}$. We have $d_5 < d_6 < d_2 < d_4 < d_1 < d_3$.\n",
    "* With $K = 1$ we would predict the same label as closest training data point, i.e. $ Y_5 = $ Green.\n",
    "* With $K = 3$ we would predict Red (for any decision threshold below 2/3) because two of the three nearest neigbors have label Red.\n",
    "* A highly non-linear decision boundary requires a flexible method. K-nearest neigbors is more flexible for small $K$s than for large $K$s. Therefore we would need a rather small $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Try without looking at the figure above:\n",
    "- Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.\n",
    "- Explain why each of the five curves has its particular shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "\n",
    "The training error declines monotonically as flexibility increases because with more flexibility the model ($\\ \\hat{f}$) fits the observed data more closely. The test error intially declines as flexibility increases but at some point it levels off and then starts to increase again (U-shape). When the model $\\ \\hat{f}$ yields a small training error but a large test error we say we are overfitting the data (i.e., our model fits too exactly to patterns in the training data that are caused by noise rather than by the true underlying function $f$). The squared bias decreases monotonically and the variance increases monotonically; as a general rule, as we use more flexible methods, the variance will increase and the bias will decrease. The irreducible error does not depend on our method so it is a horizontal line. It always lies below the test error curve because the test error will always be greater than $Var(\\ \\varepsilon)$.\n",
    "\n",
    "\"Bias\" refers to the systematic error that is introduced by approximating a complex model with a much simpler model. If we use a very simple model (i.e., an inflexible one, such as linear regression) it is essentially impossible to closely reproduce a true non-linear function $f$, and this increases the test error. \"Variance\" refers to the amount by wich our model $\\ \\hat{f}$ would fluctuate if we estimated it using different training data sets. When our method is very flexible, variance is typically high, which means that changing any training data point may cause $\\ \\hat{f}$ to change considerably. This will result in higher test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "Suppose that we take a data set with mutually distinct inputs $x_i\\neq x_j$ for $i\\neq j$, divide it into equally-sized training and test sets, and then try out two different classification procedures. First we use logistic regression and get an error rate of 20% on the training data and 30% on the test data. Next we use 1-nearest neighbors (i.e. $K = 1$) and get an average error rate (averaged over both test and training data sets) of 18%. Based on these results, which method should we prefer to use for classification of new observations? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "We should prefer logistic regression to use for classification of new observations.\n",
    "1-nearest neighbors classification has 0 error on the training set. Therefore an average error rate on equally sized training and test sets means the test error of 1-nearest neighbors classification is 36%. Because logistic regression has a lower test error rate we should prefer it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied\n",
    "#### Exercise 5\n",
    "Apply K-nearest neighbors regression to the weather data set. Use as input all predictors except `:time` and `:LUZ_wind_peak`.\n",
    "* Compute the training and the test loss for $K = 5, 10, 20, 50, 100$.\n",
    "* Which value of the hyper-parameter $K$ should we prefer to make predictions on new data?\n",
    "* Should we prefer K-nearest neighbors with optimal $K$ or multiple linear regression to make predictions on new data? *Hint*: Remember that we found a training error (RMSE) of approximately 8.1 and a test error of 8.9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/dev/MLCourse`\n"
     ]
    }
   ],
   "source": [
    "begin\n",
    "    using Pkg\n",
    "    Pkg.activate(joinpath(Pkg.devdir(), \"MLCourse\"))\n",
    "    using CSV, DataFrames, MLJ, NearestNeighborModels, MLCourse\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "\tweather_train = CSV.read(joinpath(@__DIR__, \"data\", \"weather2015-2018.csv\"),\n",
    "\t\t                     DataFrame)\n",
    "    weather_test = CSV.read(joinpath(@__DIR__, \"data\", \"weather2019-2020.csv\"),\n",
    "\t\t                    DataFrame)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_and_evalute (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin\n",
    "    function preprocess(data)\n",
    "\t\t(X = float.(select(data[1:end-5, :], Not([:LUZ_wind_peak, :time]))),\n",
    "         y = data.LUZ_wind_peak[6:end])\n",
    "    end\n",
    "    function fit_and_evalute(K, train, test)\n",
    "        X, y = preprocess(train)\n",
    "        Xtest, ytest = preprocess(test)\n",
    "        m = machine(KNNRegressor(K = K), X, y) |> fit!\n",
    "        (training_error = rmse(predict(m, X), y),\n",
    "         test_error = rmse(predict(m, Xtest), ytest))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNRegressor(K = 5, …), …).\n",
      "└ @ MLJBase /Users/simonlee/.julia/packages/MLJBase/kihuj/src/machines.jl:496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(training_error = 6.881318687330984,\n",
       " test_error = 9.948272186916055,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evalute(5, weather_train, weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNRegressor(K = 10, …), …).\n",
      "└ @ MLJBase /Users/simonlee/.julia/packages/MLJBase/kihuj/src/machines.jl:496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(training_error = 7.580827899118955,\n",
       " test_error = 9.625799175497562,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evalute(10, weather_train, weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNRegressor(K = 20, …), …).\n",
      "└ @ MLJBase /Users/simonlee/.julia/packages/MLJBase/kihuj/src/machines.jl:496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(training_error = 8.003233139572567,\n",
       " test_error = 9.534794906764708,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evalute(20, weather_train, weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNRegressor(K = 50, …), …).\n",
      "└ @ MLJBase /Users/simonlee/.julia/packages/MLJBase/kihuj/src/machines.jl:496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(training_error = 8.350455705423498,\n",
       " test_error = 9.585000368112027,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evalute(50, weather_train, weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(KNNRegressor(K = 100, …), …).\n",
      "└ @ MLJBase /Users/simonlee/.julia/packages/MLJBase/kihuj/src/machines.jl:496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(training_error = 8.575305476376224,\n",
       " test_error = 9.675105920499755,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evalute(100, weather_train, weather_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K = 20$ leads to the lowest test error among all tested $K$s and should therefore be preferred for making predictions on unseen data. However, the test error for $K = 20$ is approximately $9.5$ which is larger than the test error of multiple linear regression (approximately $8.9$). Therefore multiple linear regression is preferrable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6\n",
    "In this exercise we review the error-decomposition and the bias-variance decomposition.\n",
    "* Write a data generator where the mean of the output depends through the non-linear function $f(x) = x^2 * \\sin(x) + 4 * \\tanh(10x)$ on the input and normally distributed noise $\\epsilon$ with mean 0 and standard deviation 1.5.\n",
    "    * Take the linear function $\\hat f(x) = 2x$ and estimate its reducible error at input point $x = 0$ and at input point $x = 2$ in two ways:\n",
    "        * Using directly $f$.\n",
    "        * Using $10^5$ samples from the data generator. *Hint:* Use the samples to estimate the irreducible error and then use the error decomposition formula to compute the reducible error.\n",
    "    * Generate $10^4$ training sets of 100 data points with input $x$ normally distributed with standard deviation 2 and mean 0 and estimate the bias of linear regression at $x = 4$  in two ways:\n",
    "        * Using directly $f$.\n",
    "        * Using $10^4$ samples from the data generator. *Hint:* Use again the samples to estimate the irreducible error and use the bias-variance decomposition formula to compute the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_generator (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin\n",
    "    f(x) = x^2 * sin(x) + 4*tanh(10x)\n",
    "    data_generator(x) = DataFrame(x = x, y = f.(x) .+ 1.5*randn(length(x)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip460\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip460)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip461\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip460)\" d=\"\nM178.867 1486.45 L2352.76 1486.45 L2352.76 47.2441 L178.867 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip462\">\n    <rect x=\"178\" y=\"47\" width=\"2175\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,1486.45 178.867,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  541.182,1486.45 541.182,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  903.496,1486.45 903.496,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1265.81,1486.45 1265.81,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1628.13,1486.45 1628.13,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1990.44,1486.45 1990.44,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2352.76,1486.45 2352.76,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1486.45 178.867,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  541.182,1486.45 541.182,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  903.496,1486.45 903.496,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1265.81,1486.45 1265.81,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1628.13,1486.45 1628.13,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1990.44,1486.45 1990.44,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2352.76,1486.45 2352.76,1467.55 \n  \"/>\n<path clip-path=\"url(#clip460)\" d=\"M147.929 1532.02 L177.605 1532.02 L177.605 1535.95 L147.929 1535.95 L147.929 1532.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M198.276 1529.7 Q195.128 1529.7 193.276 1531.86 Q191.448 1534.01 191.448 1537.76 Q191.448 1541.49 193.276 1543.66 Q195.128 1545.82 198.276 1545.82 Q201.424 1545.82 203.253 1543.66 Q205.105 1541.49 205.105 1537.76 Q205.105 1534.01 203.253 1531.86 Q201.424 1529.7 198.276 1529.7 M207.559 1515.05 L207.559 1519.31 Q205.799 1518.48 203.994 1518.04 Q202.211 1517.6 200.452 1517.6 Q195.823 1517.6 193.369 1520.72 Q190.938 1523.85 190.591 1530.17 Q191.957 1528.15 194.017 1527.09 Q196.077 1526 198.554 1526 Q203.762 1526 206.772 1529.17 Q209.804 1532.32 209.804 1537.76 Q209.804 1543.08 206.656 1546.3 Q203.508 1549.52 198.276 1549.52 Q192.281 1549.52 189.11 1544.94 Q185.938 1540.33 185.938 1531.6 Q185.938 1523.41 189.827 1518.55 Q193.716 1513.66 200.267 1513.66 Q202.026 1513.66 203.809 1514.01 Q205.614 1514.36 207.559 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M510.082 1532.02 L539.758 1532.02 L539.758 1535.95 L510.082 1535.95 L510.082 1532.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M562.698 1518.36 L550.892 1536.81 L562.698 1536.81 L562.698 1518.36 M561.471 1514.29 L567.35 1514.29 L567.35 1536.81 L572.281 1536.81 L572.281 1540.7 L567.35 1540.7 L567.35 1548.85 L562.698 1548.85 L562.698 1540.7 L547.096 1540.7 L547.096 1536.19 L561.471 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M873.439 1532.02 L903.114 1532.02 L903.114 1535.95 L873.439 1535.95 L873.439 1532.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M917.235 1544.91 L933.554 1544.91 L933.554 1548.85 L911.61 1548.85 L911.61 1544.91 Q914.272 1542.16 918.855 1537.53 Q923.462 1532.88 924.642 1531.53 Q926.887 1529.01 927.767 1527.27 Q928.67 1525.51 928.67 1523.82 Q928.67 1521.07 926.725 1519.33 Q924.804 1517.6 921.702 1517.6 Q919.503 1517.6 917.05 1518.36 Q914.619 1519.13 911.841 1520.68 L911.841 1515.95 Q914.665 1514.82 917.119 1514.24 Q919.573 1513.66 921.61 1513.66 Q926.98 1513.66 930.174 1516.35 Q933.369 1519.03 933.369 1523.52 Q933.369 1525.65 932.559 1527.57 Q931.772 1529.47 929.665 1532.07 Q929.087 1532.74 925.985 1535.95 Q922.883 1539.15 917.235 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M1265.81 1517.37 Q1262.2 1517.37 1260.37 1520.93 Q1258.57 1524.47 1258.57 1531.6 Q1258.57 1538.71 1260.37 1542.27 Q1262.2 1545.82 1265.81 1545.82 Q1269.45 1545.82 1271.25 1542.27 Q1273.08 1538.71 1273.08 1531.6 Q1273.08 1524.47 1271.25 1520.93 Q1269.45 1517.37 1265.81 1517.37 M1265.81 1513.66 Q1271.62 1513.66 1274.68 1518.27 Q1277.76 1522.85 1277.76 1531.6 Q1277.76 1540.33 1274.68 1544.94 Q1271.62 1549.52 1265.81 1549.52 Q1260 1549.52 1256.92 1544.94 Q1253.87 1540.33 1253.87 1531.6 Q1253.87 1522.85 1256.92 1518.27 Q1260 1513.66 1265.81 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M1622.78 1544.91 L1639.1 1544.91 L1639.1 1548.85 L1617.15 1548.85 L1617.15 1544.91 Q1619.82 1542.16 1624.4 1537.53 Q1629.01 1532.88 1630.19 1531.53 Q1632.43 1529.01 1633.31 1527.27 Q1634.21 1525.51 1634.21 1523.82 Q1634.21 1521.07 1632.27 1519.33 Q1630.35 1517.6 1627.25 1517.6 Q1625.05 1517.6 1622.59 1518.36 Q1620.16 1519.13 1617.39 1520.68 L1617.39 1515.95 Q1620.21 1514.82 1622.66 1514.24 Q1625.12 1513.66 1627.15 1513.66 Q1632.52 1513.66 1635.72 1516.35 Q1638.91 1519.03 1638.91 1523.52 Q1638.91 1525.65 1638.1 1527.57 Q1637.32 1529.47 1635.21 1532.07 Q1634.63 1532.74 1631.53 1535.95 Q1628.43 1539.15 1622.78 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M1993.45 1518.36 L1981.64 1536.81 L1993.45 1536.81 L1993.45 1518.36 M1992.22 1514.29 L1998.1 1514.29 L1998.1 1536.81 L2003.03 1536.81 L2003.03 1540.7 L1998.1 1540.7 L1998.1 1548.85 L1993.45 1548.85 L1993.45 1540.7 L1977.85 1540.7 L1977.85 1536.19 L1992.22 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2353.16 1529.7 Q2350.01 1529.7 2348.16 1531.86 Q2346.33 1534.01 2346.33 1537.76 Q2346.33 1541.49 2348.16 1543.66 Q2350.01 1545.82 2353.16 1545.82 Q2356.31 1545.82 2358.14 1543.66 Q2359.99 1541.49 2359.99 1537.76 Q2359.99 1534.01 2358.14 1531.86 Q2356.31 1529.7 2353.16 1529.7 M2362.44 1515.05 L2362.44 1519.31 Q2360.68 1518.48 2358.88 1518.04 Q2357.1 1517.6 2355.34 1517.6 Q2350.71 1517.6 2348.25 1520.72 Q2345.82 1523.85 2345.48 1530.17 Q2346.84 1528.15 2348.9 1527.09 Q2350.96 1526 2353.44 1526 Q2358.65 1526 2361.66 1529.17 Q2364.69 1532.32 2364.69 1537.76 Q2364.69 1543.08 2361.54 1546.3 Q2358.39 1549.52 2353.16 1549.52 Q2347.17 1549.52 2343.99 1544.94 Q2340.82 1540.33 2340.82 1531.6 Q2340.82 1523.41 2344.71 1518.55 Q2348.6 1513.66 2355.15 1513.66 Q2356.91 1513.66 2358.69 1514.01 Q2360.5 1514.36 2362.44 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,1442.98 2352.76,1442.98 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,1104.93 2352.76,1104.93 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,766.878 2352.76,766.878 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,428.825 2352.76,428.825 \n  \"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  178.867,90.7729 2352.76,90.7729 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1486.45 178.867,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1442.98 197.764,1442.98 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1104.93 197.764,1104.93 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,766.878 197.764,766.878 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,428.825 197.764,428.825 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,90.7729 197.764,90.7729 \n  \"/>\n<path clip-path=\"url(#clip460)\" d=\"M50.9921 1443.43 L80.6679 1443.43 L80.6679 1447.37 L50.9921 1447.37 L50.9921 1443.43 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M94.7882 1456.33 L111.108 1456.33 L111.108 1460.26 L89.1632 1460.26 L89.1632 1456.33 Q91.8252 1453.57 96.4085 1448.94 Q101.015 1444.29 102.196 1442.95 Q104.441 1440.43 105.321 1438.69 Q106.223 1436.93 106.223 1435.24 Q106.223 1432.49 104.279 1430.75 Q102.358 1429.01 99.2558 1429.01 Q97.0567 1429.01 94.603 1429.78 Q92.1725 1430.54 89.3947 1432.09 L89.3947 1427.37 Q92.2188 1426.24 94.6724 1425.66 Q97.1261 1425.08 99.1632 1425.08 Q104.534 1425.08 107.728 1427.76 Q110.922 1430.45 110.922 1434.94 Q110.922 1437.07 110.112 1438.99 Q109.325 1440.89 107.219 1443.48 Q106.64 1444.15 103.538 1447.37 Q100.436 1450.56 94.7882 1456.33 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M130.922 1428.78 Q127.311 1428.78 125.482 1432.35 Q123.677 1435.89 123.677 1443.02 Q123.677 1450.12 125.482 1453.69 Q127.311 1457.23 130.922 1457.23 Q134.556 1457.23 136.362 1453.69 Q138.191 1450.12 138.191 1443.02 Q138.191 1435.89 136.362 1432.35 Q134.556 1428.78 130.922 1428.78 M130.922 1425.08 Q136.732 1425.08 139.788 1429.68 Q142.867 1434.27 142.867 1443.02 Q142.867 1451.74 139.788 1456.35 Q136.732 1460.93 130.922 1460.93 Q125.112 1460.93 122.033 1456.35 Q118.978 1451.74 118.978 1443.02 Q118.978 1434.27 122.033 1429.68 Q125.112 1425.08 130.922 1425.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M50.9921 1105.38 L80.6679 1105.38 L80.6679 1109.32 L50.9921 1109.32 L50.9921 1105.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M91.5706 1118.28 L99.2095 1118.28 L99.2095 1091.91 L90.8993 1093.58 L90.8993 1089.32 L99.1632 1087.65 L103.839 1087.65 L103.839 1118.28 L111.478 1118.28 L111.478 1122.21 L91.5706 1122.21 L91.5706 1118.28 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M130.922 1090.73 Q127.311 1090.73 125.482 1094.29 Q123.677 1097.84 123.677 1104.97 Q123.677 1112.07 125.482 1115.64 Q127.311 1119.18 130.922 1119.18 Q134.556 1119.18 136.362 1115.64 Q138.191 1112.07 138.191 1104.97 Q138.191 1097.84 136.362 1094.29 Q134.556 1090.73 130.922 1090.73 M130.922 1087.03 Q136.732 1087.03 139.788 1091.63 Q142.867 1096.22 142.867 1104.97 Q142.867 1113.69 139.788 1118.3 Q136.732 1122.88 130.922 1122.88 Q125.112 1122.88 122.033 1118.3 Q118.978 1113.69 118.978 1104.97 Q118.978 1096.22 122.033 1091.63 Q125.112 1087.03 130.922 1087.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M130.922 752.677 Q127.311 752.677 125.482 756.241 Q123.677 759.783 123.677 766.913 Q123.677 774.019 125.482 777.584 Q127.311 781.126 130.922 781.126 Q134.556 781.126 136.362 777.584 Q138.191 774.019 138.191 766.913 Q138.191 759.783 136.362 756.241 Q134.556 752.677 130.922 752.677 M130.922 748.973 Q136.732 748.973 139.788 753.579 Q142.867 758.163 142.867 766.913 Q142.867 775.639 139.788 780.246 Q136.732 784.829 130.922 784.829 Q125.112 784.829 122.033 780.246 Q118.978 775.639 118.978 766.913 Q118.978 758.163 122.033 753.579 Q125.112 748.973 130.922 748.973 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M91.5706 442.17 L99.2095 442.17 L99.2095 415.805 L90.8993 417.471 L90.8993 413.212 L99.1632 411.545 L103.839 411.545 L103.839 442.17 L111.478 442.17 L111.478 446.105 L91.5706 446.105 L91.5706 442.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M130.922 414.624 Q127.311 414.624 125.482 418.189 Q123.677 421.731 123.677 428.86 Q123.677 435.967 125.482 439.531 Q127.311 443.073 130.922 443.073 Q134.556 443.073 136.362 439.531 Q138.191 435.967 138.191 428.86 Q138.191 421.731 136.362 418.189 Q134.556 414.624 130.922 414.624 M130.922 410.92 Q136.732 410.92 139.788 415.527 Q142.867 420.11 142.867 428.86 Q142.867 437.587 139.788 442.193 Q136.732 446.777 130.922 446.777 Q125.112 446.777 122.033 442.193 Q118.978 437.587 118.978 428.86 Q118.978 420.11 122.033 415.527 Q125.112 410.92 130.922 410.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M94.7882 104.118 L111.108 104.118 L111.108 108.053 L89.1632 108.053 L89.1632 104.118 Q91.8252 101.363 96.4085 96.7335 Q101.015 92.0807 102.196 90.7382 Q104.441 88.215 105.321 86.4789 Q106.223 84.7197 106.223 83.0299 Q106.223 80.2753 104.279 78.5392 Q102.358 76.8031 99.2558 76.8031 Q97.0567 76.8031 94.603 77.5669 Q92.1725 78.3308 89.3947 79.8817 L89.3947 75.1595 Q92.2188 74.0253 94.6724 73.4466 Q97.1261 72.8679 99.1632 72.8679 Q104.534 72.8679 107.728 75.5531 Q110.922 78.2382 110.922 82.7289 Q110.922 84.8586 110.112 86.7798 Q109.325 88.678 107.219 91.2706 Q106.64 91.9419 103.538 95.1594 Q100.436 98.3539 94.7882 104.118 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M130.922 76.5716 Q127.311 76.5716 125.482 80.1364 Q123.677 83.678 123.677 90.8076 Q123.677 97.914 125.482 101.479 Q127.311 105.02 130.922 105.02 Q134.556 105.02 136.362 101.479 Q138.191 97.914 138.191 90.8076 Q138.191 83.678 136.362 80.1364 Q134.556 76.5716 130.922 76.5716 M130.922 72.8679 Q136.732 72.8679 139.788 77.4743 Q142.867 82.0577 142.867 90.8076 Q142.867 99.5344 139.788 104.141 Q136.732 108.724 130.922 108.724 Q125.112 108.724 122.033 104.141 Q118.978 99.5344 118.978 90.8076 Q118.978 82.0577 122.033 77.4743 Q125.112 72.8679 130.922 72.8679 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip462)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,562.053 182.405,541.655 185.943,521.681 189.482,502.135 193.02,483.022 201.199,440.517 209.378,400.385 217.557,362.662 225.737,327.374 233.916,294.542 \n  242.095,264.179 250.274,236.291 258.453,210.877 266.632,187.931 274.812,167.438 282.991,149.378 291.17,133.727 299.349,120.451 307.528,109.513 315.707,100.871 \n  323.887,94.4774 333.717,89.6917 343.548,87.9763 353.379,89.2218 363.209,93.3108 373.04,100.118 382.871,109.513 392.701,121.356 402.532,135.506 410.844,149.16 \n  419.156,164.265 427.467,180.73 435.779,198.46 444.091,217.361 452.403,237.336 460.714,258.29 469.026,280.126 487.084,330.153 505.141,382.927 523.199,437.507 \n  541.257,492.989 557.904,544.199 574.552,594.824 591.2,644.287 607.847,692.068 616.771,716.823 625.695,740.895 634.619,764.225 643.543,786.757 652.467,808.444 \n  661.391,829.24 670.315,849.108 679.239,868.014 689.579,888.679 699.918,907.979 710.257,925.89 720.597,942.393 730.936,957.48 741.275,971.152 751.615,983.416 \n  761.954,994.288 771.142,1002.8 780.331,1010.25 789.519,1016.67 798.708,1022.08 807.896,1026.52 817.084,1030.02 826.273,1032.62 835.461,1034.36 851.576,1035.47 \n  867.691,1034.33 883.805,1031.19 899.92,1026.34 935.059,1011.14 970.198,991.948 1005.55,971.248 1040.89,951.41 1060.43,941.463 1079.97,932.52 1099.52,924.728 \n  1119.06,918.169 1137.65,913.095 1156.24,909.13 1174.83,906.191 1193.43,904.107 1203.09,903.208 1212.76,902.165 1222.42,900.33 1232.09,895.935 1234.51,894.001 \n  1236.92,891.535 1239.34,888.398 1241.76,884.428 1244.17,879.436 1246.59,873.214 1249,865.553 1251.42,856.257 1253.84,845.179 1256.25,832.263 1258.67,817.58 \n  1261.09,801.362 1265.92,766.065 1270.75,730.878 1272.79,717.235 1274.82,704.666 1276.86,693.326 1278.89,683.284 1280.92,674.537 1282.96,667.029 1284.99,660.662 \n  1287.03,655.318 1291.09,647.195 1295.16,641.701 1299.23,638.037 1303.3,635.603 1319.57,631.5 1335.85,629.871 1355.71,627.706 1375.58,624.589 1395.45,620.299 \n  1415.32,614.74 1433.52,608.507 1451.72,601.206 1469.92,592.907 1488.12,583.726 1521.74,565.03 1555.36,545.332 1589.41,526.285 1623.47,510.473 1642.55,503.977 \n  1661.63,499.762 1680.71,498.285 1699.8,499.986 1717.09,504.617 1734.38,512.471 1743.03,517.684 1751.67,523.791 1760.32,530.815 1768.96,538.778 1778.86,549.069 \n  1788.76,560.635 1798.66,573.488 1808.56,587.639 1818.46,603.088 1828.36,619.83 1838.26,637.852 1848.16,657.134 1857.32,676.088 1866.49,696.07 1875.66,717.048 \n  1884.82,738.98 1893.99,761.823 1903.15,785.525 1912.32,810.028 1921.48,835.271 1939.56,886.937 1957.63,940.616 1975.7,995.641 1993.77,1051.27 2011.32,1105.09 \n  2028.87,1157.93 2046.42,1208.95 2063.96,1257.28 2072.96,1280.72 2081.95,1303.1 2090.94,1324.29 2099.94,1344.18 2108.93,1362.65 2117.93,1379.57 2126.92,1394.83 \n  2135.91,1408.31 2145.77,1420.9 2155.62,1431.08 2165.48,1438.69 2175.33,1443.61 2185.18,1445.72 2195.04,1444.88 2204.89,1440.98 2214.75,1433.93 2221.9,1426.78 \n  2229.06,1417.88 2236.22,1407.2 2243.38,1394.71 2250.53,1380.4 2257.69,1364.23 2264.85,1346.2 2272,1326.3 2279.16,1304.5 2286.32,1280.81 2293.48,1255.23 \n  2300.63,1227.75 2307.79,1198.38 2314.95,1167.14 2322.11,1134.03 2329.26,1099.08 2335.14,1069.04 2341.01,1037.78 2346.88,1005.33 2352.76,971.703 \n  \"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1501.34\" cy=\"467.569\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1306.11\" cy=\"631.533\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1522.92\" cy=\"598.648\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1758.18\" cy=\"581.029\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1791.51\" cy=\"499.104\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"974.228\" cy=\"1014\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1509\" cy=\"550.113\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1427.83\" cy=\"668.379\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1942.82\" cy=\"1008.49\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1016.1\" cy=\"968.259\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1558.06\" cy=\"566.391\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1064.23\" cy=\"909.73\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"943.632\" cy=\"1002.85\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"743.612\" cy=\"889.082\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"750.295\" cy=\"945.151\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1172.52\" cy=\"914.199\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1398.98\" cy=\"521.001\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1393.49\" cy=\"571.639\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1574.61\" cy=\"525.994\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1837.78\" cy=\"572.967\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1978.89\" cy=\"1035.5\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"991.005\" cy=\"958.492\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1379.64\" cy=\"632.37\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1019.81\" cy=\"973.546\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1310.75\" cy=\"645.181\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"993.863\" cy=\"954.447\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1177.87\" cy=\"865.764\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"569.804\" cy=\"539.097\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1051.92\" cy=\"1025.15\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1696.19\" cy=\"467.18\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"533.704\" cy=\"458.536\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1673.65\" cy=\"518.923\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"890.85\" cy=\"1008.59\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1621.85\" cy=\"513.239\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1334.98\" cy=\"621.707\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1264.11\" cy=\"800.305\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"2116.54\" cy=\"1434.39\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1212.36\" cy=\"924.493\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1108.65\" cy=\"996.079\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1147.4\" cy=\"910.809\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1204.67\" cy=\"855.148\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"698.826\" cy=\"901.361\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"789.86\" cy=\"1016.31\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"939.451\" cy=\"957.689\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"774.87\" cy=\"1083.73\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1204.87\" cy=\"839.146\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1657.06\" cy=\"518.403\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1229.13\" cy=\"955.163\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1051.26\" cy=\"978.622\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"835.238\" cy=\"1027.83\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1482.6\" cy=\"667.586\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1032.33\" cy=\"968.835\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1200.03\" cy=\"864.407\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"914.834\" cy=\"990.31\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1405\" cy=\"620.037\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1976.05\" cy=\"997.208\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1149.43\" cy=\"898.028\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1789.71\" cy=\"544.491\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"677.312\" cy=\"904.668\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"841.055\" cy=\"1047.65\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1130.16\" cy=\"967.969\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1450.57\" cy=\"620.711\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1044.45\" cy=\"949.986\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1413.72\" cy=\"638.653\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1643.33\" cy=\"438.679\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1047.6\" cy=\"986.291\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1068.96\" cy=\"922.923\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1141.72\" cy=\"987.995\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1229.31\" cy=\"867.732\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1402.48\" cy=\"588.828\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1315.21\" cy=\"572.755\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1109.87\" cy=\"877.382\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1197.96\" cy=\"866.637\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1037.14\" cy=\"896.571\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1022.54\" cy=\"934.452\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"728.65\" cy=\"973.93\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1109.47\" cy=\"843.178\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1398.49\" cy=\"571.738\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1036.18\" cy=\"944.661\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1451.35\" cy=\"508.314\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1118.99\" cy=\"894.716\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1347.39\" cy=\"589.764\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1575.27\" cy=\"471.255\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"771.956\" cy=\"964.328\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1152.07\" cy=\"832.673\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"2007.48\" cy=\"1055.18\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"878.368\" cy=\"1063.2\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1576.11\" cy=\"575.186\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1414.59\" cy=\"673.63\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1666.23\" cy=\"482.33\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"624.553\" cy=\"786.19\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1643.68\" cy=\"492.353\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1499.51\" cy=\"565.235\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1150.13\" cy=\"851.486\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1730.12\" cy=\"539.239\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1139.68\" cy=\"903.505\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1221.37\" cy=\"945.204\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1672.28\" cy=\"404.607\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"1271.03\" cy=\"821.62\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip462)\" cx=\"912.02\" cy=\"1059.38\" r=\"14.4\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<polyline clip-path=\"url(#clip462)\" style=\"stroke:#3da44d; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  178.867,1172.54 193.02,1167.26 323.887,1118.42 402.532,1089.07 469.026,1064.25 541.257,1037.29 607.847,1012.44 679.239,985.795 761.954,954.925 835.461,927.491 \n  899.92,903.434 970.198,877.205 1040.89,850.821 1119.06,821.649 1193.43,793.893 1270.75,765.034 1335.85,740.74 1415.32,711.08 1488.12,683.91 1555.36,658.816 \n  1623.47,633.397 1699.8,604.909 1768.96,579.094 1848.16,549.538 1921.48,522.172 1993.77,495.192 2063.96,468.997 2135.91,442.143 2214.75,412.722 2329.26,369.983 \n  2352.76,361.215 \n  \"/>\n<path clip-path=\"url(#clip460)\" d=\"\nM1846.57 302.578 L2280.29 302.578 L2280.29 95.2176 L1846.57 95.2176  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1846.57,302.578 2280.29,302.578 2280.29,95.2176 1846.57,95.2176 1846.57,302.578 \n  \"/>\n<polyline clip-path=\"url(#clip460)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1870.73,147.058 2015.66,147.058 \n  \"/>\n<path clip-path=\"url(#clip460)\" d=\"M2056.31 128.319 L2056.31 131.861 L2052.24 131.861 Q2049.95 131.861 2049.05 132.787 Q2048.17 133.713 2048.17 136.12 L2048.17 138.412 L2055.18 138.412 L2055.18 141.722 L2048.17 141.722 L2048.17 164.338 L2043.88 164.338 L2043.88 141.722 L2039.81 141.722 L2039.81 138.412 L2043.88 138.412 L2043.88 136.606 Q2043.88 132.278 2045.9 130.31 Q2047.91 128.319 2052.29 128.319 L2056.31 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip460)\" cx=\"1943.19\" cy=\"198.898\" r=\"23.04\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"5.12\"/>\n<path clip-path=\"url(#clip460)\" d=\"M2058.24 191.016 L2058.24 195.043 Q2056.43 194.117 2054.49 193.655 Q2052.54 193.192 2050.46 193.192 Q2047.29 193.192 2045.69 194.164 Q2044.11 195.136 2044.11 197.08 Q2044.11 198.562 2045.25 199.418 Q2046.38 200.252 2049.81 201.016 L2051.27 201.34 Q2055.8 202.312 2057.7 204.094 Q2059.62 205.854 2059.62 209.025 Q2059.62 212.636 2056.75 214.742 Q2053.91 216.849 2048.91 216.849 Q2046.82 216.849 2044.55 216.432 Q2042.31 216.039 2039.81 215.228 L2039.81 210.83 Q2042.17 212.057 2044.46 212.682 Q2046.75 213.284 2049 213.284 Q2052.01 213.284 2053.63 212.266 Q2055.25 211.224 2055.25 209.349 Q2055.25 207.613 2054.07 206.687 Q2052.91 205.761 2048.95 204.904 L2047.47 204.557 Q2043.51 203.724 2041.75 202.011 Q2039.99 200.275 2039.99 197.266 Q2039.99 193.608 2042.59 191.618 Q2045.18 189.627 2049.95 189.627 Q2052.31 189.627 2054.39 189.974 Q2056.48 190.321 2058.24 191.016 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2078.19 203.145 Q2073.03 203.145 2071.04 204.326 Q2069.05 205.506 2069.05 208.354 Q2069.05 210.622 2070.53 211.965 Q2072.03 213.284 2074.6 213.284 Q2078.14 213.284 2080.27 210.784 Q2082.42 208.261 2082.42 204.094 L2082.42 203.145 L2078.19 203.145 M2086.68 201.386 L2086.68 216.178 L2082.42 216.178 L2082.42 212.242 Q2080.97 214.603 2078.79 215.738 Q2076.61 216.849 2073.47 216.849 Q2069.49 216.849 2067.12 214.627 Q2064.79 212.381 2064.79 208.631 Q2064.79 204.256 2067.7 202.034 Q2070.64 199.812 2076.45 199.812 L2082.42 199.812 L2082.42 199.395 Q2082.42 196.455 2080.48 194.858 Q2078.56 193.238 2075.06 193.238 Q2072.84 193.238 2070.74 193.77 Q2068.63 194.303 2066.68 195.367 L2066.68 191.432 Q2069.02 190.53 2071.22 190.09 Q2073.42 189.627 2075.5 189.627 Q2081.13 189.627 2083.91 192.543 Q2086.68 195.46 2086.68 201.386 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2115.64 195.229 Q2117.24 192.358 2119.46 190.993 Q2121.68 189.627 2124.69 189.627 Q2128.74 189.627 2130.94 192.474 Q2133.14 195.298 2133.14 200.529 L2133.14 216.178 L2128.86 216.178 L2128.86 200.668 Q2128.86 196.942 2127.54 195.136 Q2126.22 193.33 2123.51 193.33 Q2120.2 193.33 2118.28 195.53 Q2116.36 197.729 2116.36 201.525 L2116.36 216.178 L2112.08 216.178 L2112.08 200.668 Q2112.08 196.918 2110.76 195.136 Q2109.44 193.33 2106.68 193.33 Q2103.42 193.33 2101.5 195.553 Q2099.58 197.752 2099.58 201.525 L2099.58 216.178 L2095.3 216.178 L2095.3 190.252 L2099.58 190.252 L2099.58 194.28 Q2101.04 191.895 2103.07 190.761 Q2105.11 189.627 2107.91 189.627 Q2110.73 189.627 2112.7 191.062 Q2114.69 192.497 2115.64 195.229 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2145.76 212.289 L2145.76 226.039 L2141.48 226.039 L2141.48 190.252 L2145.76 190.252 L2145.76 194.187 Q2147.1 191.872 2149.14 190.761 Q2151.2 189.627 2154.04 189.627 Q2158.77 189.627 2161.71 193.377 Q2164.67 197.127 2164.67 203.238 Q2164.67 209.349 2161.71 213.099 Q2158.77 216.849 2154.04 216.849 Q2151.2 216.849 2149.14 215.738 Q2147.1 214.603 2145.76 212.289 M2160.25 203.238 Q2160.25 198.539 2158.3 195.877 Q2156.38 193.192 2153 193.192 Q2149.62 193.192 2147.68 195.877 Q2145.76 198.539 2145.76 203.238 Q2145.76 207.937 2147.68 210.622 Q2149.62 213.284 2153 213.284 Q2156.38 213.284 2158.3 210.622 Q2160.25 207.937 2160.25 203.238 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2171.73 180.159 L2175.99 180.159 L2175.99 216.178 L2171.73 216.178 L2171.73 180.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2207.08 202.15 L2207.08 204.233 L2187.49 204.233 Q2187.77 208.631 2190.13 210.946 Q2192.52 213.238 2196.75 213.238 Q2199.21 213.238 2201.5 212.636 Q2203.81 212.034 2206.08 210.83 L2206.08 214.858 Q2203.79 215.83 2201.38 216.34 Q2198.98 216.849 2196.5 216.849 Q2190.29 216.849 2186.66 213.238 Q2183.05 209.627 2183.05 203.469 Q2183.05 197.104 2186.48 193.377 Q2189.92 189.627 2195.76 189.627 Q2200.99 189.627 2204.02 193.006 Q2207.08 196.363 2207.08 202.15 M2202.82 200.9 Q2202.77 197.405 2200.85 195.321 Q2198.95 193.238 2195.8 193.238 Q2192.24 193.238 2190.09 195.252 Q2187.96 197.266 2187.63 200.923 L2202.82 200.9 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2230.6 191.016 L2230.6 195.043 Q2228.79 194.117 2226.85 193.655 Q2224.9 193.192 2222.82 193.192 Q2219.65 193.192 2218.05 194.164 Q2216.48 195.136 2216.48 197.08 Q2216.48 198.562 2217.61 199.418 Q2218.74 200.252 2222.17 201.016 L2223.63 201.34 Q2228.16 202.312 2230.06 204.094 Q2231.98 205.854 2231.98 209.025 Q2231.98 212.636 2229.11 214.742 Q2226.27 216.849 2221.27 216.849 Q2219.18 216.849 2216.91 216.432 Q2214.67 216.039 2212.17 215.228 L2212.17 210.83 Q2214.53 212.057 2216.82 212.682 Q2219.11 213.284 2221.36 213.284 Q2224.37 213.284 2225.99 212.266 Q2227.61 211.224 2227.61 209.349 Q2227.61 207.613 2226.43 206.687 Q2225.27 205.761 2221.31 204.904 L2219.83 204.557 Q2215.87 203.724 2214.11 202.011 Q2212.35 200.275 2212.35 197.266 Q2212.35 193.608 2214.95 191.618 Q2217.54 189.627 2222.31 189.627 Q2224.67 189.627 2226.75 189.974 Q2228.84 190.321 2230.6 191.016 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip460)\" style=\"stroke:#3da44d; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1870.73,250.738 2015.66,250.738 \n  \"/>\n<path clip-path=\"url(#clip460)\" d=\"M2056.31 231.999 L2056.31 235.541 L2052.24 235.541 Q2049.95 235.541 2049.05 236.467 Q2048.17 237.393 2048.17 239.8 L2048.17 242.092 L2055.18 242.092 L2055.18 245.402 L2048.17 245.402 L2048.17 268.018 L2043.88 268.018 L2043.88 245.402 L2039.81 245.402 L2039.81 242.092 L2043.88 242.092 L2043.88 240.286 Q2043.88 235.958 2045.9 233.99 Q2047.91 231.999 2052.29 231.999 L2056.31 231.999 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip460)\" d=\"M2041.85 230.101 L2045.27 230.101 L2050.94 238.805 L2047.73 238.805 L2043.56 233.133 L2039.39 238.805 L2036.18 238.805 L2041.85 230.101 M2043.56 241.467 L2043.56 241.467 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin\n",
    "    using Plots\n",
    "    plot(f, xlims = (-6, 6), label = \"f\")\n",
    "    scatter!((x -> (x.x, x.y))(data_generator(2*randn(100)))..., label = \"samples\")\n",
    "    plot!(x -> 2x, label = \"f̂\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f̂ (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f̂(x) = 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(0) - f̂(0))^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics # for var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.241865382668351e-5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let samples = data_generator(fill(0, 10^5))\n",
    "\tsigma2 = var(samples.y)\n",
    "\tmean((samples.y .- f̂(0)).^2) .- sigma2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.229148966908896"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(2) - f̂(2))^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.23472335852524"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let samples = data_generator(fill(2, 10^5))\n",
    "\tsigma2 = var(samples.y)\n",
    "\tmean((samples.y .- f̂(2)).^2) .- sigma2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJLinearModels # for LinearRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_and_predict (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_and_predict()\n",
    "\tdata = data_generator(2*randn(100))\n",
    "\tm = fit!(machine(LinearRegressor(), select(data, :x), data.y), verbosity = 0)\n",
    "\tpredict(m, (x = [4],))[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Vector{Float64}:\n",
       "  3.205334960840191\n",
       "  0.44604405922995505\n",
       "  4.17862061465963\n",
       "  5.654647349530754\n",
       " 11.071462496220018\n",
       "  5.287825989551823\n",
       " -0.9182716837064155\n",
       "  2.5192584285568183\n",
       "  0.8199279014921791\n",
       "  4.088793949885932\n",
       "  4.191230699785169\n",
       "  6.097039509029098\n",
       "  3.362808613612894\n",
       "  ⋮\n",
       "  5.887941443978492\n",
       "  1.0284563716508748\n",
       "  7.603044313113509\n",
       "  3.0503858983083254\n",
       "  7.120003252906576\n",
       "  5.060152302710547\n",
       " 10.085166449270574\n",
       "  2.7283469736858743\n",
       "  8.080834417722013\n",
       "  3.99118322612397\n",
       "  1.2905561149763718\n",
       "  5.372320696153388"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [fit_and_predict() for _ in 1:10^4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.24857452605505"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Squared bias at x=4 the first way:\n",
    "(f(4) - mean(predictions))^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8978158260524385"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and squared bias at x=4 the second way:\n",
    "var(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.26133637469687"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let samples = data_generator(fill(4, 10^4))\n",
    "\tsigma2 = var(samples.y)\n",
    "\tmean((samples.y .- predictions).^2) - var(predictions) - sigma2\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
